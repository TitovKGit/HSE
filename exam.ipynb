{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMb0W7vGFtjLDzd3ruGeYsr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**1. Implement a simple feedforward neural network from scratch using Python (without a deep learning library like TensorFlow or PyTorch).**\n","\n","**Details:** Train your network on a small dataset (e.g., XOR dataset or Iris dataset) and include backpropagation for weight updates. Compare the results with an equivalent implementation using a library like TensorFlow/Keras."],"metadata":{"id":"-VMbXIbSJiYx"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.datasets import load_iris\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"WGguijy7CMcN","executionInfo":{"status":"ok","timestamp":1735370474526,"user_tz":-180,"elapsed":3352,"user":{"displayName":"Rodnenkiy","userId":"03020322099304035948"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["DEFAULT_RANDOM_SEED = 42\n","\n","def set_all_seeds(seed=DEFAULT_RANDOM_SEED):\n","\n","    np.random.seed(seed)\n","\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    import random\n","    random.seed(seed)\n","\n","    import os\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","set_all_seeds(seed=DEFAULT_RANDOM_SEED)"],"metadata":{"id":"xLMP_asAFatX","executionInfo":{"status":"ok","timestamp":1735371620105,"user_tz":-180,"elapsed":9,"user":{"displayName":"Rodnenkiy","userId":"03020322099304035948"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["SimpleNN on iris dataset"],"metadata":{"id":"OJGSqEMwJq4q"}},{"cell_type":"code","source":["class SimpleNN:\n","    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1):\n","        self.W1 = np.random.rand(input_size, hidden_size)\n","        self.W2 = np.random.rand(hidden_size, output_size)\n","        self.learning_rate = learning_rate\n","\n","    def sigmoid(self, x):\n","        return 1 / (1 + np.exp(-x))\n","\n","    def sigmoid_derivative(self, x):\n","        return x * (1 - x)\n","\n","    def forward(self, X):\n","        self.hidden = self.sigmoid(np.dot(X, self.W1))\n","        self.output = self.sigmoid(np.dot(self.hidden, self.W2))\n","        return self.output\n","\n","    def backward(self, X, y):\n","        output_error = y - self.output\n","        output_delta = output_error * self.sigmoid_derivative(self.output)\n","\n","        hidden_error = output_delta.dot(self.W2.T)\n","        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden)\n","\n","        self.W2 += self.hidden.T.dot(output_delta) * self.learning_rate\n","        self.W1 += X.T.dot(hidden_delta) * self.learning_rate\n","\n","    def train(self, X, y, epochs):\n","        for _ in range(epochs):\n","            self.forward(X)\n","            self.backward(X, y)\n","\n","iris = load_iris()\n","X = iris.data\n","y = iris.target.reshape(-1, 1)\n","\n","encoder = OneHotEncoder(sparse_output=False)\n","y = encoder.fit_transform(y)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","net = SimpleNN(input_size=4, hidden_size=5, output_size=3)\n","net.train(X_train, y_train, epochs=10000)\n","\n","predictions = net.forward(X_test)\n","predicted_classes = np.argmax(predictions, axis=1)\n","true_classes = np.argmax(y_test, axis=1)\n","\n","accuracy = np.mean(predicted_classes == true_classes)\n","print(f\"Accuracy of the custom NN on the Iris dataset: {accuracy:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1sWJLslBEqt","executionInfo":{"status":"ok","timestamp":1735371622457,"user_tz":-180,"elapsed":538,"user":{"displayName":"Rodnenkiy","userId":"03020322099304035948"}},"outputId":"943a4a89-b7b3-471d-b10d-12f63fe6aa3d"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the custom NN on the Iris dataset: 0.63\n"]}]},{"cell_type":"markdown","source":["iris dataset with an equivalent implementation using a library like TensorFlow/Keras."],"metadata":{"id":"aFlnkUbKJzX0"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7hU5Me0OA3vy","executionInfo":{"status":"ok","timestamp":1735370477077,"user_tz":-180,"elapsed":2172,"user":{"displayName":"Rodnenkiy","userId":"03020322099304035948"}},"outputId":"d5ceffc6-6b13-4df5-d40b-e8045c797bb0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 96.67%\n"]}],"source":["iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","X_train_tensor = torch.FloatTensor(X_train)\n","y_train_tensor = torch.LongTensor(y_train)\n","X_test_tensor = torch.FloatTensor(X_test)\n","y_test_tensor = torch.LongTensor(y_test)\n","\n","class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(4, 10)\n","        self.fc2 = nn.Linear(10, 3)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","model = SimpleNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","    outputs = model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor)\n","    loss.backward()\n","    optimizer.step()\n","\n","model.eval()\n","with torch.no_grad():\n","    test_outputs = model(X_test_tensor)\n","    _, predicted = torch.max(test_outputs, 1)\n","    accuracy = (predicted == y_test_tensor).float().mean()\n","    print(f'Accuracy: {accuracy.item() * 100:.2f}%')"]},{"cell_type":"markdown","source":["It can be seen that the result obtained using simpleNN, to put it mildly, is not particularly good, unlike the library implementation."],"metadata":{"id":"cZdwN8EPMT1u"}},{"cell_type":"markdown","source":["**3. Implement a network pruning technique to optimise a pre-trained neural network.**\n","\n","**Details:** Train a simple dense neural network on a dataset (e.g., Fashion-MNIST) and prune weights below a certain threshold. Compare the performance and efficiency of the pruned network with the original."],"metadata":{"id":"kzhSGaOwJ5ff"}},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader"],"metadata":{"id":"GGJrNobNI5Un","executionInfo":{"status":"ok","timestamp":1735370477509,"user_tz":-180,"elapsed":439,"user":{"displayName":"Rodnenkiy","userId":"03020322099304035948"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","class ImprovedNN(nn.Module):\n","    def __init__(self):\n","        super(ImprovedNN, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","model = ImprovedNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","def train(model, train_loader, criterion, optimizer, epochs=10):\n","    model.train()\n","    for epoch in range(epochs):\n","        for data, target in train_loader:\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","\n","def evaluate(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            output = model(data)\n","            _, predicted = torch.max(output.data, 1)\n","            total += target.size(0)\n","            correct += (predicted == target).sum().item()\n","    return correct / total\n","\n","train(model, train_loader, criterion, optimizer)\n","\n","original_accuracy = evaluate(model, test_loader)\n","print(f\"Original Model - accuracy: {original_accuracy:.4f}\")\n","\n","def prune_weights(model, threshold):\n","    with torch.no_grad():\n","        for param in model.parameters():\n","            param.data[torch.abs(param.data) < threshold] = 0\n","\n","prune_threshold = 0.05\n","prune_weights(model, prune_threshold)\n","\n","pruned_accuracy = evaluate(model, test_loader)\n","print(f\"pruned Model - accuracy: {pruned_accuracy:.4f}\")\n","\n","print(f\"accuracy difference: {pruned_accuracy - original_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"agcpWJ4TGBGx","executionInfo":{"status":"ok","timestamp":1735371894435,"user_tz":-180,"elapsed":253807,"user":{"displayName":"Rodnenkiy","userId":"03020322099304035948"}},"outputId":"258722e9-2545-4075-ed7c-5e60624a6c01"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Model - accuracy: 0.8786\n","pruned Model - accuracy: 0.8757\n","accuracy difference: -0.0029\n"]}]},{"cell_type":"markdown","source":["The results are normal, but unsatisfactory. Let's try to tune"],"metadata":{"id":"FUtSV2q9J-rG"}},{"cell_type":"code","source":["def fine_tune(model, train_loader, criterion, optimizer, epochs=5):\n","    model.train()\n","    for epoch in range(epochs):\n","        for data, target in train_loader:\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","\n","fine_tune(model, train_loader, criterion, optimizer)\n","\n","pruned_fine_tuned_accuracy = evaluate(model, test_loader)\n","print(f\"accuracy differnce after fine-tuning: {pruned_fine_tuned_accuracy - original_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSg0zj69II7M","executionInfo":{"status":"ok","timestamp":1735372028560,"user_tz":-180,"elapsed":129361,"user":{"displayName":"Rodnenkiy","userId":"03020322099304035948"}},"outputId":"e9e6ba4f-f6f4-4d39-ef2e-977c0fbacab1"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy differnce after fine-tuning: 0.0089\n"]}]},{"cell_type":"markdown","source":["After tuning, we got a small increase in accuracy."],"metadata":{"id":"H24dUEhUMz4i"}}]}